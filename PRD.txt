# Sports Fan Thread â†’ Timeline + Sentiment â€” Product Requirements Document (PRD)

## 0) One-liner

Turn chaotic live Reddit game threads into a **clean, minute-by-minute fan timeline** with sentiment and top themes â€” tuned on public Reddit threads + open NBA play-by-play. Ship a working fine-tuned model + Streamlit demo in \~4 days.

---

## 1) Output contract (required)

The model **must output only** this JSON (single game). This is the canonical contract your service and downstream clients rely on:

```json
{
  "game_id": "2019-12-01-LAL-DAL",
  "timeline": [
    {"ts": "Q1 10:32", "event": "LeBron opens the scoring in transition.", "fan_sentiment": "pos"},
    {"ts": "Q1 03:05", "event": "Mavs go on 10-2 run; Lakers cold from three.", "fan_sentiment": "neg"},
    {"ts": "Q2 01:17", "event": "Bench unit stabilizes; AD blocks two shots.", "fan_sentiment": "mixed"}
  ],
  "top_themes": ["3PT streaks", "bench impact", "ref calls"],
  "notes": "If play-by-play time unknown, use ~~MM:SS real-time bins~~."
}
```

**Schema highlights**

* `ts`: e.g., `Q3 02:13` (fallback: `00:00â€“00:59` real-time window if alignment fails).
* `fan_sentiment`: one of `pos`, `neg`, `mixed`.
* `top_themes`: 3â€“5 short phrases.
* **Strict rule:** model output must be valid JSON that validates against the timeline schema (see section *Timeline Schema*).

Acceptance tests will fail if the model emits any prose outside this JSON.

---

## 2) Goals & success metrics

### Primary goals (MVP)

1. Produce accurate, human-like, concise event summaries per 60s window for a single game.
2. Assign sensible fan sentiment (`pos|neg|mixed`) per window.
3. Produce 3â€“5 top themes per game.
4. Serve output via a Streamlit demo & an API endpoint that returns the JSON contract.

### Success metrics (targets for demo)

* **JSON validity rate:** â‰¥ 98% on held-out games.
* **Coverage (recall of big PBP events):** â‰¥ 70% of lead changes, 8+ runs, and 3+ scoring plays (Â±90s).
* **Sentiment macro-F1:** â‰¥ 0.60 vs. a reference classifier (pos/neg/mixed).
* **Redundancy:** â‰¤ 10% duplicate adjacent events.
* **Latency:** < 200ms per 60s window inference (GPU), < 80ms preferred on modest GPU w/ caching.
* **Demo readiness:** End-to-end pipeline (ingest â†’ teacher â†’ train â†’ serve) working on 100 games.

---

## 3) Scope (in / out)

### In-scope (MVP)

* Historical post-hoc mode for finished games (best first target).
* Processing NBA threads + PBP to create training data (teacher pipeline).
* QLoRA fine-tune on an 8B-class model for on-prem inference.
* Streamlit demo with timeline, hoverable comments, theme chips, and JSON copy button.

### Out-of-scope (initial)

* Live broadcast-synced, low-latency ingest from Reddit in real-time (stretch).
* Multi-sport support (stretch).
* Moderation/abuse filtering beyond simple profanity removal (follow-up).
* Production-grade scaling or multi-tenant hosted API (later).

---

## 4) Target users & user stories

### Users

* Sports fans wanting a concise timeline
* Writers/analysts looking to quickly surface fan sentiment
* Product demo viewers / recruiters (you want something resume-worthy)

### Key user stories

1. As a fan, I want a minute-by-minute timeline with sentiment, so I can relive the game's fan narrative.
2. As an analyst, I want top themes to identify recurring conversation threads.
3. As a developer, I want the model to return strict JSON so I can programmatically ingest into dashboards.

---

## 5) Data sources & required fields

**Primary**

* Reddit game threads (r/nba live threads): JSON dumps, Kaggle corpora, or your own archived `.jsonl` per game.
* NBA play-by-play (PBP) + box scores: periods, clocks, scoring events, substitutions, fouls.

**Optional enrichers**

* Team rosters / player aliases mapping (resolve nicknames).
* Schedule metadata (start time, timezone, home/away).
* Upvote counts & author ids (for weighting + per-user caps).

**Size recommendation**

* Start: 100â€“200 games â†’ produces \~10â€“20k windows.
* Target for better performance: 200â€“500 games (20â€“50k windows).

---

## 6) Teacher pipeline (create SFT pairs â€” no human labeling)

**Overview**
Automate label synthesis with PBP + Reddit signals (upvotes, comment text). Produce `(input_prompt, output_json)` pairs (one window â†’ single timeline element).

**Steps**

A. **Ingest & normalize**

* Parse Reddit `.jsonl` threads; dedupe, strip long quotes, remove images/links (keep short quotes).
* Parse PBP to canonical events with timestamps & normalized `Q` + clock.

B. **Time alignment**

* Map Reddit UTC timestamps to game clock by using schedule start time and simple linear mapping. When uncertain, use **60s real-time bins** and store overlapping PBP windows.
* If mapping fails, fallback to `window = real-time 00:00â€“00:59`.

C. **Windowing**

* Create windows: `(quarter, clock window)` default = 60-second sliding or non-overlapping bins.
* For each window, collect:

  * top-K comments by upvotes + stratified sample of others (limit token budget to \~2â€“4k chars).
  * PBP features: score\_before/after, scoring events, run length, turnovers, fouls.

D. **Teacher label generation (distant supervision)**

* **Event summary:** templated generator from PBP features + 1â€“2 short fan quotes. Keep it concise (â‰¤28 tokens preferable).
* **Sentiment:** aggregated sentiment from comments (use a small lexicon/classifier or VADER) weighted by upvotes with trimmed mean. Apply thresholds Ï„\_pos, Ï„\_neg â†’ else `mixed`.
* **Top themes:** TF-IDF / chunked n-grams across game, filter for frequency â‰¥3 windows.

E. **SFT pair composition**

* **Input prompt:** `[CONTEXT]` (game meta, window, scores), `[COMMENTS]` list, small PBP context.
* **Output:** single JSON object containing one-element `timeline` (for that window).
* Build many windows â†’ concatenate per game at serving time (or train a model variant to output full game).

---

## 7) Fine-tuning recipe (recommended: QLoRA + small DPO)

**Base models (MVP choices)**

* Llama-3.1-8B-Instruct or Qwen2-7B-Instruct.
* Use quantized weights for inference.

**SFT setup**

* Format: system message: `Output valid JSON that matches the schema. No prose.`
* Tokenization: ensure max input \~2kâ€“3k tokens (window-based training).
* Hyperparams (starting point): rank=16, Î±=32, dropout=0.05, lr=2e-4 (cosine), 3â€“4 epochs, batch size tuned to GPU memory.

**DPO / fine polishing**

* Small DPO pass (500â€“1k high-quality pairs) to prefer concise, evidence-backed events and penalize hallucinated star mentions.

**Tooling**

* PEFT/QLoRA implementation (bitsandbytes, peft, trl).
* vLLM for fast inference & batching.

**Data volume**

* 10â€“20k windows (\~100â€“200 games) for a solid demo.
* More data yields diminishing returns but improves robustness to noise.

---

## 8) Evaluation (automatic + quick human checks)

**Automatic metrics**

* **JSON validity rate:** fraction of outputs that pass schema validator (target â‰¥98%).
* **Coverage:** % of PBP â€œbig eventsâ€ covered in timeline (Â±90s).
* **Redundancy:** duplicate suppression rate (target â‰¤10%).
* **Sentiment F1:** macro-F1 vs. reference aggregated classifier.
* **ROUGE-1/2:** sanity check vs. teacher outputs (do not over-optimize).
* **Latency:** per-window inference time.

**Quick human checks**

* Sample 10 games; human inspect: faithfulness, unnatural phrasing, hallucinations.
* Check hallucinated player names and any invented claims.

**Acceptance criteria**

* JSON validity â‰¥98%, Coverage â‰¥70%, Sentiment Macro-F1 â‰¥0.60, Redundancy â‰¤10%.

---

## 9) Guardrails & inference rules

* **Schema enforcement:** run validator; on invalid output, retry once with a constrained instruction: â€œReturn only valid JSON; shorten event to â‰¤120 chars.â€
* **Evidence constraint:** event must contain â‰¥1 token present in comments/PBP for that window (soft rule; log violations).
* **Dedup filter:** suppress events within 90s that are near-duplicates (cosine similarity threshold).
* **User caps:** cap contribution influence per Reddit author (prevent single-user dominance).
* **No hallucinated names:** if name token not present in evidence, avoid explicit star attribution.

---

## 10) Minimal demo (Streamlit)

**Core screens**

* **Game selector:** choose a finished game (upload PBP + thread or pick pre-ingested game).
* **Center:** timeline rows (one per window) with:

  * `ts`, one-line `event` summary, emoji sentiment badge.
  * Hover or expand: shows 2â€“3 representative comments and PBP snippet.
* **Right rail:** `top_themes` chips â€” click to filter timeline.
* **Buttons:** `Copy JSON`, `Download JSON`, `Regenerate game` (re-run model).
* **Mode toggle:** post-hoc vs. live-simulated (for demo, simulate streaming playback).

**UX constraints**

* Always display the evidence (comments + PBP) behind an event to build trust.
* Show a small â€œconfidenceâ€ indicator per row (optional).

---

## 11) API & serve contract

**Endpoint**: `POST /v1/timeline/generate`
**Payload**:

```json
{
  "game_id": "2019-12-01-LAL-DAL",
  "reddit_thread_json": "...",   // optional if pre-ingested
  "pbp_json": "...",            // optional if pre-ingested
  "mode": "post_hoc"            // "post_hoc" or "live_sim"
}
```

**Response**: the JSON output contract (only the schema JSON).

**Error behavior**

* 400 if inputs missing / malformed.
* 500 if model errors; return structured error JSON (not in contract).

---

## 12) File layout (recommended)

```
fan-timeline/
â”œâ”€ configs/
â”‚  â””â”€ nba.yaml
â”œâ”€ data/
â”‚  â”œâ”€ reddit/                 # jsonl per game
â”‚  â””â”€ pbp/                    # pbp json per game
â”œâ”€ schema/
â”‚  â””â”€ timeline.schema.json
â”œâ”€ src/
â”‚  â””â”€ timeline/
â”‚     â”œâ”€ ingest_reddit.py
â”‚     â”œâ”€ parse_pbp.py
â”‚     â”œâ”€ align_time.py
â”‚     â”œâ”€ windowing.py
â”‚     â”œâ”€ teacher.py
â”‚     â”œâ”€ make_sft.py
â”‚     â”œâ”€ train_sft.py
â”‚     â”œâ”€ eval_harness.py
â”‚     â””â”€ serve.py
â””â”€ app/
   â””â”€ streamlit_app.py
```

---

## 13) 4-day build plan (focus & deliverables)

**Day 1 â€” Ingest & alignment**

* Tasks:

  * Collect 100 games: Reddit threads + PBP (jsonl).
  * Implement `ingest_reddit.py`, `parse_pbp.py`, `align_time.py`.
  * Produce windowed comment groups.
* Deliverable: 100 ingested games; windowed `.jsonl` ready for teacher.

**Day 2 â€” Teacher & SFT pairs**

* Tasks:

  * Implement `teacher.py` template writer + weak sentiment rules.
  * Run over windows â†’ produce 10k SFT pairs.
  * Validate sample outputs against timeline schema.
* Deliverable: `sft_data.jsonl` (10k pairs), baseline stats.

**Day 3 â€” Fine-tune & evaluate**

* Tasks:

  * Quick QLoRA run on 8B-instruct (3 epochs).
  * Implement `eval_harness.py`: JSON validity, coverage, sentiment F1.
  * Tweak teacher thresholds; re-run small DPO pass if needed.
* Deliverable: fine-tuned model checkpoint + evaluation report.

**Day 4 â€” Demo & polish**

* Tasks:

  * Build `serve.py` + Streamlit `streamlit_app.py`.
  * Hook model to demo; implement copy/download JSON.
  * Run human spot checks; fix schema failures.
* Deliverable: Streamlit demo + API endpoint ready for presentation.

---

## 14) Roles / ownership (example for 1â€“2 people)

* **Data engineer (you):** ingest, time alignment, windowing.
* **ML engineer (you):** teacher pipeline, fine-tune, eval harness.
* **Full-stack (you):** Streamlit app + serve wrapper.
  *(If solo, split tasks by day per plan above.)*

---

## 15) Risks & mitigations

| Risk                                     | Impact | Mitigation                                                                                       |
| ---------------------------------------- | -----: | ------------------------------------------------------------------------------------------------ |
| Noisy Reddit chatter â†’ irrelevant events | Medium | Upvote weighting, token caps, keyword filters; start with high-signal windows (high engagement). |
| Time alignment errors                    |   High | Fall back to real-time bins; surface `notes` indicating uncertain mapping.                       |
| Hallucinated player claims               |   High | Evidence token constraint + DPO penalize unsupported names.                                      |
| Schema breakage                          |   High | Strict validator + auto-retry with constrained instruction.                                      |
| Sentiment bias from loud users           | Medium | Cap per-user influence; trimmed mean.                                                            |

---

## 16) Acceptance criteria (MVP)

1. Run pipeline on 100 games â†’ produce `sft_data.jsonl`.
2. Fine-tuned model produces valid JSON for â‰¥98% of test games.
3. Coverage â‰¥70% on held-out games by `eval_harness.py`.
4. Streamlit demo loads a finished game, shows timeline with hoverable comments, and â€œCopy JSONâ€ exports the contract.

---

## 17) Example SFT pair (reminder)

**Input (truncated)**

```
[CONTEXT]
game_id=LAL@DAL 2019-12-01
quarter=Q3 window=03:00â€“02:00 score_before=68-73 score_after=74-73

[COMMENTS]
â€¢ luka cooking again ðŸ˜­
â€¢ 8-0 run wtf are we doing
â€¢ KCP finally hits one!
â€¢ refs missing obvious travels
```

**Output**

```json
{"timeline":[{"ts":"Q3 02:13","event":"Mavs push an 8â€“0 run behind Doncic drives; Lakers stop the slide with a KCP three.","fan_sentiment":"mixed"}]}
```

---

## 18) Next immediate steps (you can run this now)

1. Assemble 100 games (reddit + pbp) into `data/` (Day 1).
2. I can generate the scaffold files (`ingest_reddit.py`, `align_time.py`, `teacher.py`, `make_sft.py`, `train_sft.py`, `streamlit_app.py`) ready-to-run â€” say the word and Iâ€™ll drop the scaffold code so you can plug data and start training immediately.

---
